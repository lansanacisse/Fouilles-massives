{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aPJuaqJAqUqG"
      },
      "source": [
        "# **Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "MZ2RCGvLcpe4"
      },
      "outputs": [],
      "source": [
        "# import library\n",
        "import pandas as pd\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from imblearn.over_sampling import ADASYN\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, f1_score, accuracy_score, confusion_matrix\n",
        "from sklearn.svm import SVC\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import GridSearchCV"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6nsiGkb_psD5"
      },
      "source": [
        "# **Importation des données**  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "udNG-ZNtQNx4",
        "outputId": "4708002e-15a4-4b07-ec4c-36cf998f0cb1"
      },
      "outputs": [],
      "source": [
        "# Ajustez le chemin selon l'emplacement réel de votre fichier\n",
        "data = pd.read_csv(\"guillaume.txt\", sep=\";\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NUdO2CFjqC9c"
      },
      "source": [
        "# **Traitement de données**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "TU12riN-Nn9V"
      },
      "outputs": [],
      "source": [
        "def nettoyer_colonnes_par_indices(data, indices_colonnes):\n",
        "    \"\"\"\n",
        "    Nettoie plusieurs colonnes spécifiées par leurs indices en supprimant les espaces,\n",
        "    convertissant les valeurs en numérique, supprimant les valeurs non valides,\n",
        "    et en les convertissant en entiers.\n",
        "\n",
        "    Args:\n",
        "        data (pd.DataFrame): Le DataFrame à traiter.\n",
        "        indices_colonnes (list): Liste des indices des colonnes à nettoyer.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: Le DataFrame avec les colonnes nettoyées.\n",
        "    \"\"\"\n",
        "    # Parcourir les indices des colonnes\n",
        "    for indice in indices_colonnes:\n",
        "        # Obtenir le nom de la colonne depuis l'indice\n",
        "        colonne = data.columns[indice]\n",
        "\n",
        "        # Supprimer les espaces\n",
        "        data[colonne] = data[colonne].astype(str).str.strip()\n",
        "        # Convertir en numérique (remplace les erreurs par NaN)\n",
        "        data[colonne] = pd.to_numeric(data[colonne], errors='coerce')\n",
        "        # Supprimer les lignes avec des NaN dans la colonne\n",
        "        data = data.dropna(subset=[colonne])\n",
        "        # Convertir les valeurs en entiers\n",
        "        data[colonne] = data[colonne].astype(int)\n",
        "\n",
        "    return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1-sgqbElNwA_",
        "outputId": "142b1f7b-76c6-4b21-83e1-4d93e1369fa6"
      },
      "outputs": [],
      "source": [
        "# Liste des indices des colonnes à nettoyer\n",
        "indices_colonnes = [1,2,5,6,7,8,9,15,16,22]\n",
        "\n",
        "# Nettoyage des colonnes\n",
        "data = nettoyer_colonnes_par_indices(data, indices_colonnes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 843
        },
        "id": "hyBxVt9lP-Ib",
        "outputId": "f2543012-d33c-4178-8577-6ee97857c840"
      },
      "outputs": [],
      "source": [
        "# verifier les types de mes données\n",
        "data.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3QTKe1aJW71V",
        "outputId": "d35d4d88-f219-407c-f872-cae158d86596"
      },
      "outputs": [],
      "source": [
        "col_flot = [\"Montant\", \"TauxImpNb_RB\",\"TauxImpNB_CPM\", \"CA3TRetMtt\", \"CA3TR\",\"ScoringFP1\", \t\"ScoringFP2\", \t\"ScoringFP3\"]\n",
        "col_str = [\"ZIBZIN\",\"IDAvisAutorisationCheque\"]\n",
        "co_date = [\"DateTransaction\"]\n",
        "col_heure = [\"Heure\"]\n",
        "# recuperer toutes les colonnnes qui ne foont pas parti de col_flot, col_str, col_heure, col_date dans col_int\n",
        "col_int = [col for col in data.columns if col not in col_flot and col not in col_str and col not in col_heure and col not in co_date]\n",
        "# afficher le nombre de chacune des liste\n",
        "print(\"col_flot :\", len(col_flot))\n",
        "print(\"col_str :\", len(col_str))\n",
        "print(\"col_int :\", len(col_int))\n",
        "print(\"co_date :\", len(co_date))\n",
        "print(\"col_heure :\", len(col_heure))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "NR0TpIsHYsLF"
      },
      "outputs": [],
      "source": [
        "for col in col_flot:\n",
        "    # Remplacer les virgules par des points dans les colonnes de type string\n",
        "    data[col] = data[col].astype(str).str.replace(',', '.', regex=False)\n",
        "\n",
        "    # Convertir les colonnes au type float\n",
        "    data[col] = data[col].astype(float)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "jK-2RMY4au7-"
      },
      "outputs": [],
      "source": [
        "# Convertir en int\n",
        "for col in col_int:\n",
        "    # Vérifier si la colonne n'est pas déjà de type int\n",
        "    if data[col].dtype != 'int64':\n",
        "        # Remplacer les virgules par des points, si nécessaire\n",
        "        data[col] = data[col].astype(str).str.replace(',', '.')\n",
        "        # Convertir en type float puis en int (pour éviter les problèmes avec les décimales)\n",
        "        data[col] = data[col].astype(float).astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "AnI1pQEHbppu"
      },
      "outputs": [],
      "source": [
        "# convertir la col_date en type date\n",
        "data['DateTransaction'] = pd.to_datetime(data['DateTransaction'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "xoxa4Lb2cmAe"
      },
      "outputs": [],
      "source": [
        "# Conversion des secondes depuis minuit en format timedelta\n",
        "data['Heure'] = pd.to_timedelta(data['Heure'], unit='s')\n",
        "\n",
        "# Convertir en format HH:MM:SS en chaîne (ou datetime.time si nécessaire)\n",
        "data['Heure'] = data['Heure'].apply(lambda x: (pd.Timestamp(\"00:00:00\") + x).time())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **Analyse Exploratoire des Données**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# liste des elements en flagImpaye\n",
        "data['FlagImpaye'].value_counts()\n",
        "\n",
        "# Graphique des transactions circulaires flagImpaye\n",
        "plt.figure(figsize=(6, 6))\n",
        "data['FlagImpaye'].value_counts().plot.pie(autopct='%1.1f%%')\n",
        "plt.title('Répartition des transactions')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "# selectionner toutes les colonnes sauf DateTransaction et Heure\n",
        "NUMERIC_FEATURES = [col for col in data.columns if col not in ['DateTransaction', 'Heure','ZIBZIN','IDAvisAutorisationCheque']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "# Filtrer les transactions refusées\n",
        "data_refuse = data[data['FlagImpaye'] == 1]\n",
        "\n",
        "# Extraire le jour de la semaine et le mois\n",
        "data_refuse['JourSemaine'] = data_refuse['DateTransaction'].dt.day_name()\n",
        "data_refuse['Mois'] = data_refuse['DateTransaction'].dt.strftime('%b')  # Nom abrégé du mois\n",
        "\n",
        "# Grouper par mois et jour de la semaine et compter les transactions refusées\n",
        "grouped_data = data_refuse.groupby(['Mois', 'JourSemaine']).size().unstack()\n",
        "\n",
        "# Ordonner les mois et les jours de la semaine\n",
        "mois_ord = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
        "jours_ord = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
        "\n",
        "# Réorganiser les données selon l'ordre voulu\n",
        "grouped_data = grouped_data.reindex(mois_ord, axis=0)\n",
        "grouped_data = grouped_data[jours_ord]\n",
        "\n",
        "# Création du graphique en barres groupées\n",
        "plt.figure(figsize=(12, 6))\n",
        "grouped_data.plot(kind='bar', figsize=(12, 6), rot=0)\n",
        "\n",
        "# Ajouter des labels et un titre\n",
        "plt.title('Transactions refusées par Mois et Jour de la Semaine')\n",
        "plt.xlabel('Mois')\n",
        "plt.ylabel('Nombre de Transactions Refusées')\n",
        "plt.legend(title='Jour de la semaine')\n",
        "\n",
        "# Afficher le graphique\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Création du boxplot avec une palette de couleurs améliorée\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.boxplot(x='FlagImpaye', y='Montant', data=data, palette=['#2E86C1', '#E74C3C'])  # Bleu pour 0, Rouge pour 1\n",
        "\n",
        "# Ajout du titre et des labels\n",
        "plt.title('Montant des Transactions selon le FlagImpaye', fontsize=14, fontweight='bold', pad=15)\n",
        "plt.xlabel('FlagImpaye', fontsize=12)\n",
        "plt.ylabel('Montant (€)', fontsize=12)\n",
        "\n",
        "# Affichage du graphique\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Ajoutons le jour de la semaine\n",
        "data_refuse['JourSemaine'] = data_refuse['DateTransaction'].dt.day_name()\n",
        "\n",
        "# Analyse croisée : jour de la semaine par mois\n",
        "plt.figure(figsize=(15, 8))\n",
        "cross_tab = pd.crosstab(data_refuse['Mois'], data_refuse['JourSemaine'])\n",
        "sns.heatmap(cross_tab, cmap='YlOrRd', annot=True, fmt='d')\n",
        "plt.title('Répartition des transactions refusées par jour de la semaine et par mois')\n",
        "plt.xlabel('Jour de la semaine')\n",
        "plt.ylabel('Mois')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# distrubution des transactions selon flagImpaye, calcul le pourcentage de chaque valeur\n",
        "data['FlagImpaye'].value_counts(normalize=True) * 100\n",
        "\n",
        "# Nombre et pourcentage de transactions de chaque classe\n",
        "nombre_transactions = data['FlagImpaye'].value_counts()\n",
        "pourcentage_transactions = data['FlagImpaye'].value_counts(normalize=True) * 100\n",
        "#afficher le nombre et le pourcentage dans un tableau\n",
        "pd.DataFrame({'Nombre de transactions': nombre_transactions, 'Pourcentage de transactions (%)': pourcentage_transactions})\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **Partie 2**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Séparation des features et la cible**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Définir les plages de dates pour l'apprentissage et le test\n",
        "train_start_date = \"2017-02-01\"\n",
        "train_end_date = \"2017-08-31\"\n",
        "test_start_date = \"2017-09-01\"\n",
        "test_end_date = \"2017-11-30\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Définir les plages de dates pour l'apprentissage et le test\n",
        "train_start_date = \"2017-02-01\"\n",
        "train_end_date = \"2017-08-31\"\n",
        "test_start_date = \"2017-09-01\"\n",
        "test_end_date = \"2017-11-30\"\n",
        "\n",
        "# Séparer les ensembles d'apprentissage et de test\n",
        "train_data = data[(data['DateTransaction'] >= train_start_date) & (data['DateTransaction'] <= train_end_date)]\n",
        "test_data = data[(data['DateTransaction'] >= test_start_date) & (data['DateTransaction'] <= test_end_date)]\n",
        "\n",
        "# Sélection des features et de la cible\n",
        "X_train = train_data.drop(['IDAvisAutorisationCheque', 'ZIBZIN', 'Heure', 'FlagImpaye', 'DateTransaction'], axis=1)\n",
        "y_train = train_data['FlagImpaye']\n",
        "X_test = test_data.drop(['IDAvisAutorisationCheque', 'ZIBZIN', 'Heure', 'FlagImpaye', 'DateTransaction'], axis=1)\n",
        "y_test = test_data['FlagImpaye']\n",
        "amounts_test = test_data['Montant']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Vérifier les dimensions\n",
        "print(f\"Dimensions des données d'entraînement: {X_train.shape}, {y_train.shape}\")\n",
        "print(f\"Dimensions des données de test: {X_test.shape}, {y_test.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Définition de la matrice des coûts\n",
        "def compute_margin(y_true, y_pred, amounts):\n",
        "    r = 0.05  # Taux de marge\n",
        "    margin = 0\n",
        "    \n",
        "    for yt, yp, m in zip(y_true, y_pred, amounts):\n",
        "        if yt == 0 and yp == 0:  # TN : transaction acceptée et correcte\n",
        "            margin += r * m\n",
        "        elif yt == 1 and yp == 0:  # FN : transaction frauduleuse acceptée\n",
        "            if m <= 20:\n",
        "                loss = 0\n",
        "            elif m <= 50:\n",
        "                loss = 0.2 * m\n",
        "            elif m <= 100:\n",
        "                loss = 0.3 * m\n",
        "            elif m <= 200:\n",
        "                loss = 0.5 * m\n",
        "            else:\n",
        "                loss = 0.8 * m\n",
        "            margin -= loss\n",
        "        elif yt == 0 and yp == 1:  # FP : transaction correcte refusée\n",
        "            margin += 0.7 * r * m\n",
        "        # TP (fraude bien détectée) n'apporte ni perte ni gain\n",
        "    \n",
        "    return margin"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"# Liste des modèles à tester\n",
        "models = {\n",
        "    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced'),\n",
        "    \"XGBoost\": XGBClassifier(eval_metric='logloss', random_state=42, learning_rate=0.1, n_estimators=100),\n",
        "    \"Neural Network\": MLPClassifier(hidden_layer_sizes=(100,), max_iter=500, random_state=42)\n",
        "}\n",
        "\n",
        "# Tester chaque modèle\n",
        "results = {}\n",
        "for name, model in models.items():\n",
        "    print(f\"\\nEntraînement du modèle: {name}\")\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    margin = compute_margin(y_test, y_pred, amounts_test)\n",
        "    results[name] = {\n",
        "        \"F1-score\": f1,\n",
        "        \"Marge\": margin,\n",
        "        \"Matrice de confusion\": cm\n",
        "    }\n",
        "    print(f\"F1-score: {f1:.4f}\")\n",
        "    print(f\"Marge générée: {margin:.2f}\")\n",
        "    print(\"Matrice de confusion:\")\n",
        "    print(cm)\"\"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Paramètres de la recherche sur grille\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'learning_rate': [0.01, 0.1, 0.2],\n",
        "    'max_depth': [3, 6, 9],\n",
        "    'subsample': [0.8, 1.0],\n",
        "    'colsample_bytree': [0.8, 1.0]\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Création et configuration du modèle XGBoost de base\n",
        "gxboost = XGBClassifier(eval_metric='logloss', random_state=42)\n",
        "\n",
        "# Configuration de la recherche sur grille\n",
        "grid_search = GridSearchCV(\n",
        "    estimator=gxboost,\n",
        "    param_grid=param_grid,\n",
        "    scoring='f1',\n",
        "    cv=3,\n",
        "    verbose=2,\n",
        "    n_jobs=-1\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Entraînement de la recherche sur grille\n",
        "print(\"Début de la recherche sur grille...\")\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Récupération du meilleur modèle\n",
        "best_xgboost = grid_search.best_estimator_\n",
        "\n",
        "# Affichage des meilleurs paramètres\n",
        "print(\"\\nMeilleurs paramètres trouvés:\")\n",
        "for param, value in grid_search.best_params_.items():\n",
        "    print(f\"{param}: {value}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Évaluation du modèle\n",
        "models = {\n",
        "    \"Optimized XGBoost\": best_xgboost\n",
        "}\n",
        "\n",
        "# Fonction pour afficher la matrice de confusion\n",
        "def plot_confusion_matrix(cm, title='Matrice de Confusion'):\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "    plt.title(title)\n",
        "    plt.ylabel('Vraie classe')\n",
        "    plt.xlabel('Classe prédite')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test des modèles\n",
        "results = {}\n",
        "for name, model in models.items():\n",
        "    print(f\"\\nEntraînement du modèle: {name}\")\n",
        "    \n",
        "    # Prédictions et métriques\n",
        "    y_pred = model.predict(X_test)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    margin = compute_margin(y_test, y_pred, amounts_test)\n",
        "    \n",
        "    # Stockage des résultats\n",
        "    results[name] = {\n",
        "        \"F1-score\": f1,\n",
        "        \"Marge\": margin,\n",
        "        \"Matrice de confusion\": cm\n",
        "    }\n",
        "    \n",
        "    # Affichage des résultats\n",
        "    print(f\"F1-score: {f1:.4f}\")\n",
        "    print(f\"Marge générée: {margin:.2f}\")\n",
        "    print(\"Matrice de confusion:\")\n",
        "    print(cm)\n",
        "    \n",
        "    # Visualisation de la matrice de confusion\n",
        "    plot_confusion_matrix(cm, f'Matrice de Confusion - {name}')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Affichage de l'importance des caractéristiques\n",
        "feature_importance = pd.DataFrame({\n",
        "    'feature': X_train.columns,\n",
        "    'importance': best_xgboost.feature_importances_\n",
        "})\n",
        "feature_importance = feature_importance.sort_values('importance', ascending=False)\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x='importance', y='feature', data=feature_importance)\n",
        "plt.title('Importance des caractéristiques')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "6nsiGkb_psD5",
        "GLx9yOUep3GQ",
        "NUdO2CFjqC9c",
        "cjjF3UpPLE-A",
        "7MgS9llEcdhB",
        "my2vfDWKnfmQ",
        "bLLv_WKpSl1G",
        "UPX8Gh_b79n0"
      ],
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "env10",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
